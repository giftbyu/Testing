{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe9vkEvFABbN"
      },
      "source": [
        "[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "# How to Train YOLOv8 Object Detection on a Custom Dataset\n",
        "\n",
        "---\n",
        "\n",
        "[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset)\n",
        "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/wuZtUMEiKWY)\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)\n",
        "\n",
        "Ultralytics YOLOv8 is a popular version of the YOLO (You Only Look Once) object detection and image segmentation model developed by Ultralytics. The YOLOv8 model is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection and image segmentation tasks. It can be trained on large datasets and is capable of running on a variety of hardware platforms, from CPUs to GPUs.\n",
        "\n",
        "## Disclaimer\n",
        "\n",
        "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
        "\n",
        "## Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the accompanying [Blog Post](https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/).\n",
        "\n",
        "## Pro Tip: Use GPU Acceleration\n",
        "\n",
        "If you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.\n",
        "\n",
        "## Steps in this Tutorial\n",
        "\n",
        "In this tutorial, we are going to cover:\n",
        "\n",
        "- Before you start\n",
        "- Install YOLOv8\n",
        "- CLI Basics\n",
        "- Inference with Pre-trained COCO Model\n",
        "- Roboflow Universe\n",
        "- Preparing a custom dataset\n",
        "- Custom Training\n",
        "- Validate Custom Model\n",
        "- Inference with Custom Model\n",
        "\n",
        "**Let's begin!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "d39d68b6-04c4-4c15-b831-4b3c1ab71622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul  5 15:09:57 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "408b45c6-b9ca-4517-f2fd-a0c4db933d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Install YOLOv8\n",
        "\n",
        "YOLOv8 can be installed in two ways - from the source and via pip. This is because it is the first iteration of YOLO to have an official package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_OjgQgoUE0s",
        "outputId": "4b19bfbe-9d50-4218-8d26-220a35df7238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "a2b2a31e-205e-41e5-944e-8c853eb98c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.162 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 41.7/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnnZSm5OQfPQ"
      },
      "source": [
        "## CLI Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K33S7zlkQku0"
      },
      "source": [
        "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://docs.ultralytics.com/usage/cli/).\n",
        "\n",
        "```\n",
        "yolo task=detect    mode=train    model=yolov8n.yaml      args...\n",
        "          classify       predict        yolov8n-cls.yaml  args...\n",
        "          segment        val            yolov8n-seg.yaml  args...\n",
        "                         export         yolov8n.pt        format=onnx  args...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with Pre-trained COCO Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2Xtaekw3271"
      },
      "source": [
        "## Roboflow Universe\n",
        "\n",
        "Need data for your project? Before spending time on annotating, check out Roboflow Universe, a repository of more than 110,000 open-source datasets that you can use in your projects. You'll find datasets containing everything from annotated cracks in concrete to plant images with disease annotations.\n",
        "\n",
        "\n",
        "[![Roboflow Universe](https://media.roboflow.com/notebooks/template/uni-banner-frame.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672878480290)](https://universe.roboflow.com/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JHICVjZbVKn"
      },
      "source": [
        "## Preparing a custom dataset\n",
        "\n",
        "Building a custom dataset can be a painful process. It might take dozens or even hundreds of hours to collect images, label them, and export them in the proper format. Fortunately, Roboflow makes this process as straightforward and fast as possible. Let me show you how!\n",
        "\n",
        "### Step 1: Creating project\n",
        "\n",
        "Before you start, you need to create a Roboflow [account](https://app.roboflow.com/login). Once you do that, you can create a new project in the Roboflow [dashboard](https://app.roboflow.com/). Keep in mind to choose the right project type. In our case, Object Detection.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img\n",
        "    width=\"640\"\n",
        "    src=\"https://media.roboflow.com/preparing-custom-dataset-example/creating-project.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1672929799852\"\n",
        "  >\n",
        "</div>\n",
        "\n",
        "### Step 2: Uploading images\n",
        "\n",
        "Next, add the data to your newly created project. You can do it via API or through our [web interface](https://docs.roboflow.com/adding-data/object-detection).\n",
        "\n",
        "If you drag and drop a directory with a dataset in a [supported format](https://roboflow.com/formats), the Roboflow dashboard will automatically read the images and annotations together.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img\n",
        "    width=\"640\"\n",
        "    src=\"https://media.roboflow.com/preparing-custom-dataset-example/uploading-images.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1672929808290\"\n",
        "  >\n",
        "</div>\n",
        "\n",
        "### Step 3: Labeling\n",
        "\n",
        "If you only have images, you can label them in [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img\n",
        "    width=\"640\"\n",
        "    src=\"https://user-images.githubusercontent.com/26109316/210901980-04861efd-dfc0-4a01-9373-13a36b5e1df4.gif\"\n",
        "  >\n",
        "</div>\n",
        "\n",
        "### Step 4: Generate new dataset version\n",
        "\n",
        "Now that we have our images and annotations added, we can Generate a Dataset Version. When Generating a Version, you may elect to add preprocessing and augmentations. This step is completely optional, however, it can allow you to significantly improve the robustness of your model.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img\n",
        "    width=\"640\"\n",
        "    src=\"https://media.roboflow.com/preparing-custom-dataset-example/generate-new-version.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1673003597834\"\n",
        "  >\n",
        "</div>\n",
        "\n",
        "### Step 5: Exporting dataset\n",
        "\n",
        "Once the dataset version is generated, we have a hosted dataset we can load directly into our notebook for easy training. Click `Export` and select the `YOLO v8` dataset format. (Formerly, we used to use `Yolov5`, as the gif shows)\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img\n",
        "    width=\"640\"\n",
        "    src=\"https://media.roboflow.com/preparing-custom-dataset-example/export.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1672943313709\"\n",
        "  >\n",
        "</div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfMNIMqYKipQ"
      },
      "source": [
        "🟢 Tip: The examples below work even if you use our non-custom model. However, you won't be able to deploy it to Roboflow. To do that, create a custom dataset as described below or fork (copy) one into your workspace from Universe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSd93ZJzZZKt",
        "outputId": "121417db-a97c-4f04-f003-a5cb09fcd51c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in BISINDOv2-1 to yolov8:: 100%|██████████| 49064/49064 [00:00<00:00, 56576.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to BISINDOv2-1 in yolov8:: 100%|██████████| 6475/6475 [00:00<00:00, 10127.21it/s]\n"
          ]
        }
      ],
      "source": [
        "%mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "%pip install roboflow --quiet\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"moOAxzoPZOtIzhyyco0r\")\n",
        "project = rf.workspace(\"bisindo-qndjb\").project(\"bisindov2\")\n",
        "dataset = project.version(1).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOjEkBRpfy9q"
      },
      "source": [
        "`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2YkphuiaE7_",
        "outputId": "d9d27bbc-2a49-4f54-85e7-d14d59eaa7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n",
            "100% 21.5M/21.5M [00:00<00:00, 159MB/s]\n",
            "Ultralytics 8.3.162 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/datasets/BISINDOv2-1/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=800, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 26.2MB/s]\n",
            "Overriding model.yaml nc=80 with nc=36\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2129980  ultralytics.nn.modules.head.Detect           [36, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,149,532 parameters, 11,149,516 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 80.6MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 614.6±201.0 MB/s, size: 15.6 KB)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/BISINDOv2-1/train/labels... 2661 images, 0 backgrounds, 0 corrupt: 100% 2661/2661 [00:01<00:00, 2581.97it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/BISINDOv2-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 518.4±197.3 MB/s, size: 16.3 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/BISINDOv2-1/valid/labels... 572 images, 0 backgrounds, 0 corrupt: 100% 572/572 [00:00<00:00, 1389.57it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/BISINDOv2-1/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00025, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 800 train, 800 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100      5.62G      1.317      5.444      1.667          9        800: 100% 167/167 [01:17<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:08<00:00,  2.14it/s]\n",
            "                   all        572        572      0.637      0.409      0.533      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/100      6.82G      1.041      2.572      1.398          6        800: 100% 167/167 [01:14<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.27it/s]\n",
            "                   all        572        572      0.703      0.686      0.771      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/100      6.86G       1.01      1.866      1.364         13        800: 100% 167/167 [01:13<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.46it/s]\n",
            "                   all        572        572      0.894      0.773      0.885       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/100      6.89G     0.9582       1.52       1.32          9        800: 100% 167/167 [01:13<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.35it/s]\n",
            "                   all        572        572      0.908      0.859      0.949      0.741\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/100      6.93G     0.9174      1.262      1.273          7        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.33it/s]\n",
            "                   all        572        572      0.922       0.88       0.96      0.752\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/100      6.97G     0.9019      1.133      1.266          9        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.53it/s]\n",
            "                   all        572        572      0.906      0.913      0.968       0.77\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/100      7.01G     0.8722      1.028      1.237         10        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.32it/s]\n",
            "                   all        572        572      0.923      0.916      0.964      0.764\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      8/100      7.04G     0.8421     0.9536      1.209          9        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.952      0.946      0.982      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      9/100      7.07G     0.8019     0.8779      1.189         11        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.49it/s]\n",
            "                   all        572        572      0.944      0.923      0.978      0.778\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     10/100      7.11G     0.7953     0.8519      1.185         14        800: 100% 167/167 [01:11<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572      0.925      0.947      0.983      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     11/100      7.15G     0.7832     0.7749      1.178          6        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.52it/s]\n",
            "                   all        572        572      0.966      0.911      0.982      0.794\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     12/100      7.19G     0.7709     0.7835      1.163          8        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.38it/s]\n",
            "                   all        572        572      0.958       0.96       0.98      0.799\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     13/100      7.21G     0.7509     0.7288      1.143          6        800: 100% 167/167 [01:12<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572      0.956      0.968      0.985       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     14/100      7.26G     0.7355     0.7059      1.142         11        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.48it/s]\n",
            "                   all        572        572      0.964      0.965      0.983        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     15/100      7.29G     0.7133     0.6855      1.125         15        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.964      0.968      0.989      0.817\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     16/100      7.34G      0.715     0.6653      1.127          9        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.49it/s]\n",
            "                   all        572        572      0.963      0.979      0.986      0.819\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     17/100      7.36G     0.7087     0.6476      1.121          9        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.48it/s]\n",
            "                   all        572        572      0.968      0.968      0.988      0.824\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     18/100      5.75G     0.6901      0.607      1.103          7        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.33it/s]\n",
            "                   all        572        572      0.972      0.977      0.987      0.817\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     19/100      6.91G     0.6888     0.6054      1.112          7        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.51it/s]\n",
            "                   all        572        572      0.967      0.976      0.986      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     20/100      6.91G      0.683     0.5847      1.106          7        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.31it/s]\n",
            "                   all        572        572       0.97      0.961      0.986      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     21/100      6.91G      0.674     0.5776       1.09         10        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.41it/s]\n",
            "                   all        572        572      0.971      0.973      0.985      0.827\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     22/100      6.91G     0.6585     0.5562      1.093         10        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.52it/s]\n",
            "                   all        572        572      0.957      0.983      0.988      0.832\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     23/100      6.91G     0.6717     0.5711      1.097          5        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.33it/s]\n",
            "                   all        572        572      0.973      0.988      0.988      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     24/100      6.92G     0.6442     0.5382      1.082          6        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.50it/s]\n",
            "                   all        572        572      0.979      0.978      0.988      0.827\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     25/100      6.95G     0.6423     0.5342      1.085         11        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.35it/s]\n",
            "                   all        572        572      0.978      0.984      0.989      0.827\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     26/100      6.99G     0.6262     0.5159      1.077          4        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572      0.972       0.98      0.991      0.836\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     27/100      7.03G     0.6249     0.5185      1.073          6        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.53it/s]\n",
            "                   all        572        572      0.967      0.975      0.991      0.833\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     28/100      7.06G     0.6317     0.5025      1.072         10        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.975      0.979       0.99      0.836\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     29/100      7.09G     0.6161     0.5034      1.063          9        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.34it/s]\n",
            "                   all        572        572      0.968      0.975      0.984      0.833\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     30/100      7.13G     0.6092     0.4793      1.061         12        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.50it/s]\n",
            "                   all        572        572      0.971      0.982      0.989      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     31/100      7.18G     0.6186     0.4763      1.069          6        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.972      0.985       0.99      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     32/100      7.21G     0.5943     0.4634      1.046          8        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.47it/s]\n",
            "                   all        572        572      0.978      0.989      0.987      0.842\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     33/100      7.24G     0.5981     0.4711      1.059         14        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.38it/s]\n",
            "                   all        572        572      0.976      0.988      0.988      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     34/100      7.28G     0.5907     0.4513      1.058         14        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.34it/s]\n",
            "                   all        572        572      0.968      0.987      0.989      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     35/100      7.32G     0.5823     0.4504      1.045          8        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.52it/s]\n",
            "                   all        572        572      0.977      0.985      0.986      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     36/100      7.35G     0.5881     0.4536      1.052         12        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572      0.979      0.982      0.986      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     37/100      5.69G     0.5816     0.4602       1.05         13        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.975      0.982      0.989      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     38/100      6.84G     0.5721     0.4373      1.036         16        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.48it/s]\n",
            "                   all        572        572      0.985      0.986      0.987      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     39/100      6.84G     0.5669     0.4263      1.033          5        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.39it/s]\n",
            "                   all        572        572      0.975      0.982      0.989      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     40/100      6.84G     0.5679     0.4266      1.029          7        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.52it/s]\n",
            "                   all        572        572      0.981      0.986      0.985      0.846\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     41/100      6.84G      0.549     0.4186      1.019         12        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.33it/s]\n",
            "                   all        572        572      0.974      0.983      0.986      0.848\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     42/100      6.84G     0.5546     0.4231      1.026          5        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572      0.974      0.988      0.986      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     43/100      6.88G     0.5536     0.4192      1.032          4        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.54it/s]\n",
            "                   all        572        572      0.975      0.987       0.99      0.856\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     44/100      6.91G     0.5449     0.4146       1.03         12        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.985      0.983      0.985      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     45/100      6.95G     0.5403     0.4073      1.018          8        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.34it/s]\n",
            "                   all        572        572      0.981      0.989      0.987      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     46/100      6.99G     0.5363     0.4141      1.019          9        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.52it/s]\n",
            "                   all        572        572      0.979      0.991      0.988      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     47/100      7.02G     0.5367     0.3965      1.025         10        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.978      0.985      0.984      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     48/100      7.06G     0.5311     0.3904      1.016         11        800: 100% 167/167 [01:11<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.979      0.985      0.986      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     49/100      7.09G     0.5324     0.3895      1.016          6        800: 100% 167/167 [01:13<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.51it/s]\n",
            "                   all        572        572      0.979      0.989      0.986      0.856\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     50/100      7.14G     0.5114     0.3765      1.007         10        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.35it/s]\n",
            "                   all        572        572      0.981       0.98      0.985      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     51/100      7.17G     0.5233     0.3805      1.009         10        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572       0.98      0.986      0.988      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     52/100      7.21G     0.5057     0.3723      1.002         11        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.47it/s]\n",
            "                   all        572        572      0.975      0.988      0.986      0.858\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     53/100      7.24G      0.511     0.3766      1.003         10        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572      0.978      0.985      0.986      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     54/100      7.28G        0.5     0.3664     0.9993         11        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.52it/s]\n",
            "                   all        572        572      0.974      0.987      0.987      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     55/100      7.32G     0.4983     0.3633     0.9982          7        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.47it/s]\n",
            "                   all        572        572      0.982      0.989      0.988       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     56/100      7.35G     0.4892     0.3604     0.9971          9        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.38it/s]\n",
            "                   all        572        572      0.982      0.988      0.988      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     57/100      7.38G     0.4883     0.3511     0.9901         10        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:06<00:00,  2.60it/s]\n",
            "                   all        572        572      0.984      0.988      0.986      0.858\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     58/100      5.47G     0.4852     0.3522     0.9936         11        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.40it/s]\n",
            "                   all        572        572      0.983      0.983      0.987       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     59/100      5.47G     0.4766     0.3356     0.9849         11        800: 100% 167/167 [01:12<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.34it/s]\n",
            "                   all        572        572      0.984      0.989       0.99      0.864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     60/100      5.47G     0.4696     0.3407     0.9832          9        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.53it/s]\n",
            "                   all        572        572      0.982      0.986      0.987      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     61/100      5.47G     0.4849     0.3452      0.993          7        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572      0.982      0.989      0.986       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     62/100      5.53G     0.4623     0.3234      0.976          8        800: 100% 167/167 [01:12<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.41it/s]\n",
            "                   all        572        572       0.98      0.986      0.985      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     63/100      5.53G     0.4755     0.3308     0.9859         12        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.52it/s]\n",
            "                   all        572        572      0.975      0.986      0.987      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     64/100      5.63G     0.4741     0.3406     0.9849         11        800: 100% 167/167 [01:12<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.979      0.988      0.991      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     65/100      5.66G     0.4577     0.3225     0.9754          9        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.44it/s]\n",
            "                   all        572        572      0.986      0.989      0.987      0.865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     66/100      5.79G     0.4525     0.3209     0.9694         10        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.53it/s]\n",
            "                   all        572        572      0.982      0.989      0.988      0.864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     67/100      5.82G     0.4497     0.3146     0.9673         11        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.34it/s]\n",
            "                   all        572        572      0.982      0.992      0.989      0.864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     68/100      5.92G     0.4421     0.3094     0.9578          7        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.48it/s]\n",
            "                   all        572        572      0.983       0.99       0.99       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     69/100      5.95G     0.4451     0.3089      0.967          9        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.50it/s]\n",
            "                   all        572        572      0.984       0.99      0.989      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     70/100      6.05G     0.4338     0.3071     0.9524          5        800: 100% 167/167 [01:11<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.41it/s]\n",
            "                   all        572        572      0.983       0.99      0.989      0.872\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     71/100      6.08G     0.4408     0.3105     0.9689         11        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.47it/s]\n",
            "                   all        572        572      0.983      0.992      0.989      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     72/100      6.12G     0.4445     0.3158     0.9683          7        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.40it/s]\n",
            "                   all        572        572      0.984      0.989      0.989      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     73/100       6.2G     0.4319     0.3016     0.9582         11        800: 100% 167/167 [01:11<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.38it/s]\n",
            "                   all        572        572      0.984      0.991      0.989      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     74/100      6.33G     0.4294     0.3016     0.9574         10        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.55it/s]\n",
            "                   all        572        572      0.979      0.992      0.989      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     75/100      6.37G      0.414     0.2926     0.9543          9        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.44it/s]\n",
            "                   all        572        572      0.982      0.991      0.988      0.872\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     76/100       6.4G     0.4267     0.3106     0.9614          4        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.39it/s]\n",
            "                   all        572        572      0.983      0.992      0.989      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     77/100      6.49G     0.4232     0.2989     0.9548          8        800: 100% 167/167 [01:12<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.53it/s]\n",
            "                   all        572        572      0.982      0.991      0.989      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     78/100       6.6G     0.4102     0.2825      0.952          9        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.38it/s]\n",
            "                   all        572        572      0.984       0.99      0.989      0.877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     79/100      6.63G     0.4127     0.2836     0.9511          8        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572      0.981       0.99      0.989      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     80/100      6.67G      0.407     0.2823     0.9501          8        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.57it/s]\n",
            "                   all        572        572      0.985       0.99      0.989      0.872\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     81/100      6.75G     0.4031     0.2818     0.9447          7        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.982      0.991      0.989      0.874\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     82/100      6.85G     0.4017     0.2755     0.9461         12        800: 100% 167/167 [01:11<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572      0.983      0.992      0.989      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     83/100      6.89G     0.3975     0.2749     0.9436          6        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.54it/s]\n",
            "                   all        572        572      0.979      0.991      0.989      0.872\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     84/100      6.98G     0.3935     0.2679     0.9396          8        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.981       0.99      0.989      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     85/100      7.01G     0.3961     0.2743      0.938          5        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.38it/s]\n",
            "                   all        572        572      0.984      0.991      0.987      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     86/100      7.14G     0.3907     0.2706     0.9402         11        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.52it/s]\n",
            "                   all        572        572      0.985      0.991      0.988      0.874\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     87/100      7.18G     0.3943     0.2678     0.9431          7        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.32it/s]\n",
            "                   all        572        572      0.985      0.991      0.988      0.876\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     88/100      7.21G     0.3813     0.2646     0.9292         10        800: 100% 167/167 [01:12<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.985      0.989      0.988      0.876\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     89/100       7.3G     0.3907     0.2694     0.9442          7        800: 100% 167/167 [01:13<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.39it/s]\n",
            "                   all        572        572      0.985       0.99      0.988      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     90/100       7.4G      0.377     0.2616     0.9364          9        800: 100% 167/167 [01:12<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.47it/s]\n",
            "                   all        572        572      0.984       0.99      0.988      0.874\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     91/100       5.5G     0.3207      0.197     0.9081          5        800: 100% 167/167 [01:13<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.50it/s]\n",
            "                   all        572        572      0.986       0.99      0.988      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     92/100       5.5G      0.307     0.1898     0.9037          5        800: 100% 167/167 [01:11<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.36it/s]\n",
            "                   all        572        572      0.984      0.991      0.988      0.877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     93/100       5.5G     0.3024     0.1861     0.9008          5        800: 100% 167/167 [01:11<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.986      0.988      0.988      0.878\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     94/100      5.55G     0.2978     0.1848     0.8918          5        800: 100% 167/167 [01:11<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.53it/s]\n",
            "                   all        572        572      0.985       0.99      0.988      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     95/100      5.55G     0.2963     0.1818     0.8902          5        800: 100% 167/167 [01:12<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.54it/s]\n",
            "                   all        572        572      0.985      0.991      0.988      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     96/100      5.55G     0.2947     0.1819     0.9022          5        800: 100% 167/167 [01:11<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.38it/s]\n",
            "                   all        572        572      0.986       0.99      0.988      0.876\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     97/100      5.64G     0.2886     0.1786     0.8896          5        800: 100% 167/167 [01:11<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                   all        572        572      0.985      0.989      0.988      0.879\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     98/100      5.74G     0.2863     0.1748     0.8823          5        800: 100% 167/167 [01:10<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.40it/s]\n",
            "                   all        572        572      0.985      0.989      0.988       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     99/100      5.77G     0.2826      0.175     0.8834          5        800: 100% 167/167 [01:11<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:06<00:00,  2.58it/s]\n",
            "                   all        572        572      0.985       0.99      0.988      0.879\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "    100/100      5.81G       0.28     0.1727     0.8807          5        800: 100% 167/167 [01:11<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:07<00:00,  2.41it/s]\n",
            "                   all        572        572      0.986       0.99      0.988      0.879\n",
            "\n",
            "100 epochs completed in 2.236 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.162 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,139,516 parameters, 0 gradients, 28.5 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:09<00:00,  1.93it/s]\n",
            "                   all        572        572      0.985      0.989      0.988      0.879\n",
            "                     A         17         17      0.995          1      0.995      0.938\n",
            "                   Apa         15         15      0.997          1      0.995       0.86\n",
            "                     B         20         20      0.994          1      0.995      0.816\n",
            "                     C         23         23      0.994          1      0.995      0.902\n",
            "                     D         17         17      0.887          1      0.958      0.901\n",
            "                     E         14         14      0.989          1      0.995      0.851\n",
            "                     F         16         16          1          1      0.995      0.954\n",
            "                     G         19         19      0.994          1      0.995      0.834\n",
            "                     H         16         16      0.991          1      0.995      0.904\n",
            "                  Halo         21         21      0.993          1      0.995      0.882\n",
            "                     I         14         14      0.989          1      0.995      0.806\n",
            "              ILoveYou         12         12          1          1      0.995      0.847\n",
            "                     J         20         20      0.993          1      0.995      0.838\n",
            "                     K         10         10      0.986          1      0.995      0.913\n",
            "                  Kamu         14         14      0.999          1      0.995      0.779\n",
            "                     L         14         14      0.992          1      0.995      0.923\n",
            "                     M         14         14      0.821          1       0.99      0.926\n",
            "                 Malam         17         17          1          1      0.995      0.854\n",
            "                     N         23         23      0.994      0.913      0.947      0.863\n",
            "                  Nama         14         14      0.992          1      0.995      0.876\n",
            "                     O         10         10      0.994          1      0.995      0.898\n",
            "                     P         12         12      0.991      0.833      0.903       0.83\n",
            "                  Pagi         16         16          1          1      0.995      0.826\n",
            "                     Q         16         16      0.993          1      0.995      0.887\n",
            "                     R         19         19      0.942      0.947       0.92      0.671\n",
            "                     S         16         16      0.991          1      0.995      0.865\n",
            "                  Saya         16         16          1       0.96      0.995        0.8\n",
            "   Selamat-Terimakasih         12         12          1          1      0.995      0.913\n",
            "                 Siapa         17         17          1          1      0.995      0.931\n",
            "                     T         15         15          1      0.974      0.995      0.949\n",
            "                     U         17         17      0.991          1      0.995      0.975\n",
            "                     V         17         17       0.99          1      0.995      0.942\n",
            "                     W         15         15          1      0.984      0.995      0.958\n",
            "                     X         13         13          1          1      0.995      0.942\n",
            "                     Y         14         14      0.989          1      0.995      0.852\n",
            "                     Z         17         17      0.992          1      0.995      0.928\n",
            "Speed: 0.4ms preprocess, 6.9ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "output_folder=\"/content/datasets\"\n",
        "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=100 imgsz=800 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDgVtfHOjAQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9556d0b-f062-4149-f94c-ca457488d93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best.pt  last.pt\n"
          ]
        }
      ],
      "source": [
        "%ls {HOME}/runs/detect/train/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J35i8Ofhjxa"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-urTWUkhRmn"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/results.png', width=800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI4nADCCj3F5"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/train_batch0.jpg', width=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODk1VTlevxn"
      },
      "source": [
        "## Validate Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpyuwrNlXc1P"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFHpWRPe4nxo"
      },
      "outputs": [],
      "source": [
        "# Validate model\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('runs/detect/train/weights/best.pt')\n",
        "# Validate the model\n",
        "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
        "metrics.box.map    # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps   # a list contains map50-95 of each category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWJgM4vnrlWD",
        "outputId": "e46f7d22-6db1-4f3a-d38c-edb43170adac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Impor library YOLO\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Muat model terbaik Anda yang sudah dilatih dari file .pt\n",
        "model = YOLO('runs/detect/train/weights/best.pt')\n",
        "\n",
        "# Ekspor model ke format TFLite\n",
        "# Argumen `imgsz` harus sesuai dengan yang Anda gunakan saat pelatihan\n",
        "model.export(format='tflite', imgsz=800)\n",
        "\n",
        "print(\"\\nEkspor ke TFLite selesai!\")\n",
        "print(\"File TFLite Anda akan berada di folder: /content/runs/detect/train/weights/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o-8uht3c_Z0f",
        "outputId": "4f17c358-4960-4330-f1b9-4ab1019e9a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.58 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 11,139,516 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train/weights/best.pt' with input shape (1, 3, 800, 800) BCHW and output shape(s) (1, 40, 13125) (21.5 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'onnx>=1.12.0', 'onnx2tf>1.17.5,<=1.26.3', 'onnxslim>=0.1.31', 'tflite_support', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting sng4onnx>=1.0.1\n",
            "  Downloading sng4onnx-1.0.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting onnx_graphsurgeon>=0.3.26\n",
            "  Downloading onnx_graphsurgeon-0.5.2-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnx2tf<=1.26.3,>1.17.5\n",
            "  Downloading onnx2tf-1.26.3-py3-none-any.whl.metadata (146 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 146.6/146.6 kB 10.1 MB/s eta 0:00:00\n",
            "Collecting onnxslim>=0.1.31\n",
            "  Downloading onnxslim-0.1.46-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting tflite_support\n",
            "  Downloading tflite_support-0.4.4-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx_graphsurgeon>=0.3.26) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxslim>=0.1.31) (1.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxslim>=0.1.31) (24.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tflite_support) (1.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite_support) (24.3.25)\n",
            "Collecting protobuf>=3.20.2 (from onnx>=1.12.0)\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from tflite_support)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pybind11>=2.6.0 (from tflite_support)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->tflite_support) (1.17.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxslim>=0.1.31) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support) (2.22)\n",
            "Downloading sng4onnx-1.0.4-py3-none-any.whl (5.9 kB)\n",
            "Downloading onnx_graphsurgeon-0.5.2-py2.py3-none-any.whl (56 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.4/56.4 kB 275.4 MB/s eta 0:00:00\n",
            "Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 295.0 MB/s eta 0:00:00\n",
            "Downloading onnx2tf-1.26.3-py3-none-any.whl (445 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 445.6/445.6 kB 328.2 MB/s eta 0:00:00\n",
            "Downloading onnxslim-0.1.46-py3-none-any.whl (142 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.6/142.6 kB 354.6 MB/s eta 0:00:00\n",
            "Downloading tflite_support-0.4.4-cp310-cp310-manylinux2014_x86_64.whl (60.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 MB 243.2 MB/s eta 0:00:00\n",
            "Downloading onnxruntime_gpu-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (291.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 291.5/291.5 MB 190.9 MB/s eta 0:00:00\n",
            "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 230.3 MB/s eta 0:00:00\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 243.3/243.3 kB 225.6 MB/s eta 0:00:00\n",
            "Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 196.0 MB/s eta 0:00:00\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 236.6 MB/s eta 0:00:00\n",
            "Installing collected packages: sng4onnx, pybind11, protobuf, onnx2tf, humanfriendly, sounddevice, onnx, coloredlogs, tflite_support, onnxslim, onnxruntime-gpu, onnx_graphsurgeon\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnx2tf-1.26.3 onnx_graphsurgeon-0.5.2 onnxruntime-gpu-1.20.1 onnxslim-0.1.46 protobuf-3.20.3 pybind11-2.13.6 sng4onnx-1.0.4 sounddevice-0.5.1 tflite_support-0.4.4\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 29.9s, installed 7 packages: ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'onnx>=1.12.0', 'onnx2tf>1.17.5,<=1.26.3', 'onnxslim>=0.1.31', 'tflite_support', 'onnxruntime-gpu']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.1...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.11M/1.11M [00:00<00:00, 28.6MB/s]\n",
            "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100%|██████████| 1/1 [00:00<00:00, 47.23file/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.46...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.3s, saved as 'runs/detect/train/weights/best.onnx' (43.0 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.26.3...\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 128.1s, saved as 'runs/detect/train/weights/best_saved_model' (108.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.17.1...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as 'runs/detect/train/weights/best_saved_model/best_float32.tflite' (42.8 MB)\n",
            "\n",
            "Export complete (131.2s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/train/weights/best_saved_model/best_float32.tflite imgsz=800  \n",
            "Validate:        yolo val task=detect model=runs/detect/train/weights/best_saved_model/best_float32.tflite imgsz=800 data=/content/datasets/BISINDOv2-1/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'runs/detect/train/weights/best_saved_model/best_float32.tflite'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  Export model to tflite\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('runs/detect/train/weights/best.pt')  # load a custom trained model\n",
        "\n",
        "# Export the model\n",
        "model.export(format='onnx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "1vg02RkF_jMz",
        "outputId": "7cd5e71e-4b57-4cf8-f5bf-97be0a130541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/runs/detect/train/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/train/weights/last.pt (deflated 10%)\n",
            "  adding: content/runs/detect/train/weights/best.pt (deflated 10%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_3897d9e8-8f5e-4bb2-adbe-e79e07af8d56\", \"train_folder.zip\", 11390848)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Nama folder yang ingin di-zip\n",
        "folder_to_zip = \"/content/runs/detect/train/weights\"  # Sesuaikan path folder Anda\n",
        "output_zip = \"/content/train_folder.zip\"  # Nama file ZIP yang dihasilkan\n",
        "\n",
        "# Membuat arsip ZIP\n",
        "!zip -r {output_zip} {folder_to_zip}\n",
        "\n",
        "# Mendownload file ZIP\n",
        "files.download(output_zip)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with Custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97QX6wVtsWkg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjc1ctZykYuf",
        "outputId": "57521a98-7550-457c-be26-be89a77d49d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Ultralytics 8.3.108 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,007,793 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "image 1/50 /content/datasets/Kibo-3/valid/images/post_3-13-_png.rf.9085a4e7cb4d8ce73e6990f4300d1c8f.jpg: 800x800 1 compass, 1 diamond, 11.4ms\n",
            "image 2/50 /content/datasets/Kibo-3/valid/images/post_3-14-_png.rf.32e59e7ff3b26f3a721185a23a334337.jpg: 800x800 1 coin, 10.2ms\n",
            "image 3/50 /content/datasets/Kibo-3/valid/images/post_3-15-_png.rf.0fbf235853915b153b0a6f06af871071.jpg: 800x800 1 coral, 10.1ms\n",
            "image 4/50 /content/datasets/Kibo-3/valid/images/post_3-16-_png.rf.a3046808c1479d44a7d905753647c326.jpg: 800x800 1 coin, 10.0ms\n",
            "image 5/50 /content/datasets/Kibo-3/valid/images/post_3-17-_png.rf.3dbf57c39d6cbf1205c11cf8bf75b4a0.jpg: 800x800 1 shell, 10.1ms\n",
            "image 6/50 /content/datasets/Kibo-3/valid/images/post_3-18-_png.rf.b353bc57b851f2a5a68ee8fb1e5f95a5.jpg: 800x800 1 coral, 1 emerald, 10.1ms\n",
            "image 7/50 /content/datasets/Kibo-3/valid/images/post_3-2-_png.rf.ed719bf7502031b87161cbcaa586e8bb.jpg: 800x800 1 key, 10.0ms\n",
            "image 8/50 /content/datasets/Kibo-3/valid/images/post_3-21-_png.rf.63ea809104002ebd3b39039264240500.jpg: 800x800 1 key, 10.0ms\n",
            "image 9/50 /content/datasets/Kibo-3/valid/images/post_3-28-_png.rf.a2098aabae391429c5935e353fb68c94.jpg: 800x800 2 keys, 10.1ms\n",
            "image 10/50 /content/datasets/Kibo-3/valid/images/post_3-3-_png.rf.f53a77ec840ead92013dcb4610b79cc4.jpg: 800x800 1 diamond, 1 fossil, 10.1ms\n",
            "image 11/50 /content/datasets/Kibo-3/valid/images/post_3-33-_png.rf.50f25e362b91785eaeec373450c0d1d6.jpg: 800x800 1 crystal, 1 key, 8.7ms\n",
            "image 12/50 /content/datasets/Kibo-3/valid/images/post_3-4-_png.rf.aa75af799f0b12a0491574a1fd639e9a.jpg: 800x800 1 crystal, 1 shell, 8.7ms\n",
            "image 13/50 /content/datasets/Kibo-3/valid/images/post_3-6-_png.rf.8c16d52294b5c48197b7c70d50092359.jpg: 800x800 1 diamond, 9.2ms\n",
            "image 14/50 /content/datasets/Kibo-3/valid/images/post_3_png.rf.8db7bc1ea2396c87e80ab8e7f8aebb90.jpg: 800x800 1 crystal, 1 shell, 8.7ms\n",
            "image 15/50 /content/datasets/Kibo-3/valid/images/post_4-1-_png.rf.1d5d7ef209d24f12ca54391262628724.jpg: 800x800 1 Treasure_box, 9.7ms\n",
            "image 16/50 /content/datasets/Kibo-3/valid/images/post_4-12-_png.rf.d201cbface01c364af1e43761f39e48b.jpg: 800x800 1 Treasure_box, 8.7ms\n",
            "image 17/50 /content/datasets/Kibo-3/valid/images/post_4-13-_png.rf.400752aafd83a013dd3ccaa41a062157.jpg: 800x800 1 letter, 8.7ms\n",
            "image 18/50 /content/datasets/Kibo-3/valid/images/post_4-14-_png.rf.dfd113538d14e7519ad3fbfb86ae79a7.jpg: 800x800 1 Treasure_box, 8.7ms\n",
            "image 19/50 /content/datasets/Kibo-3/valid/images/post_4-16-_png.rf.f7ef4c8a09d183b31c10f076ed3081e9.jpg: 800x800 1 diamond, 1 letter, 8.6ms\n",
            "image 20/50 /content/datasets/Kibo-3/valid/images/post_4-17-_png.rf.576b69b6704d32ce23bc2c0b454a636f.jpg: 800x800 1 coral, 1 diamond, 11.1ms\n",
            "image 21/50 /content/datasets/Kibo-3/valid/images/post_4-19-_png.rf.653bbc8ae19ca7861aef607f601083be.jpg: 800x800 1 key, 7.9ms\n",
            "image 22/50 /content/datasets/Kibo-3/valid/images/post_4-2-_png.rf.adedcfa92167c23ebd8d0b105ed5afbc.jpg: 800x800 1 coin, 8.6ms\n",
            "image 23/50 /content/datasets/Kibo-3/valid/images/post_4-21-_png.rf.b2336717eb9e4975d80a5018a18c28cd.jpg: 800x800 1 emerald, 1 shell, 7.8ms\n",
            "image 24/50 /content/datasets/Kibo-3/valid/images/post_4-23-_png.rf.1cb311e0a90619332cd851928a23b25d.jpg: 800x800 1 crystal, 1 letter, 7.8ms\n",
            "image 25/50 /content/datasets/Kibo-3/valid/images/post_4-24-_png.rf.6aa18f40d6f22bb8ca544f877ce7c92e.jpg: 800x800 1 letter, 8.3ms\n",
            "image 26/50 /content/datasets/Kibo-3/valid/images/post_4-25-_png.rf.ff69bd2b9c3c13183228f7c9a4a664cd.jpg: 800x800 2 letters, 10.7ms\n",
            "image 27/50 /content/datasets/Kibo-3/valid/images/post_4-28-_png.rf.495f61b45a6fb4b5020381f17e3c3257.jpg: 800x800 1 emerald, 1 shell, 7.8ms\n",
            "image 28/50 /content/datasets/Kibo-3/valid/images/post_4-29-_png.rf.9b4894828d3a72198966c93bd9a9efdb.jpg: 800x800 1 coin, 1 crystal, 7.8ms\n",
            "image 29/50 /content/datasets/Kibo-3/valid/images/post_4-3-_png.rf.5dbc5b1c0a438ffa2df59abb46390556.jpg: 800x800 1 crystal, 1 key, 7.8ms\n",
            "image 30/50 /content/datasets/Kibo-3/valid/images/post_4-30-_png.rf.bebb96700b6514e753e6bd89eab4ad6d.jpg: 800x800 3 shells, 7.8ms\n",
            "image 31/50 /content/datasets/Kibo-3/valid/images/post_4-31-_png.rf.81e5b1ad43d0874b93fccd3773c845d9.jpg: 800x800 1 coral, 1 diamond, 10.8ms\n",
            "image 32/50 /content/datasets/Kibo-3/valid/images/post_4-32-_png.rf.778befb51df47d2867f20ab727714501.jpg: 800x800 1 fossil, 7.8ms\n",
            "image 33/50 /content/datasets/Kibo-3/valid/images/post_4-33-_png.rf.7771fc59b21a7082ec3708d1b156d810.jpg: 800x800 1 coral, 7.8ms\n",
            "image 34/50 /content/datasets/Kibo-3/valid/images/post_4-34-_png.rf.77fe2c151784b7078cbc39ea11d3e7cc.jpg: 800x800 1 emerald, 2 fossils, 7.8ms\n",
            "image 35/50 /content/datasets/Kibo-3/valid/images/post_4-35-_png.rf.d94a90f8022d7b2af200e196d4dd711c.jpg: 800x800 3 compasss, 1 crystal, 8.1ms\n",
            "image 36/50 /content/datasets/Kibo-3/valid/images/post_4-36-_png.rf.55f10e3f7eabc5f96b1d3db1a718cc55.jpg: 800x800 1 fossil, 7.8ms\n",
            "image 37/50 /content/datasets/Kibo-3/valid/images/post_4-37-_png.rf.90486d0e7b6adf90ac1758703145e014.jpg: 800x800 1 coin, 1 emerald, 7.8ms\n",
            "image 38/50 /content/datasets/Kibo-3/valid/images/post_4-39-_png.rf.a681d92e707f35a9df3af76dce82a6fd.jpg: 800x800 1 Treasure_box, 7.8ms\n",
            "image 39/50 /content/datasets/Kibo-3/valid/images/post_4-4-_png.rf.65a1d0f09556fc039b14d7f2c2e7e396.jpg: 800x800 2 coins, 7.8ms\n",
            "image 40/50 /content/datasets/Kibo-3/valid/images/post_4-6-_png.rf.f4f36a126e1c6d790a63f28b1ffa102b.jpg: 800x800 1 crystal, 7.8ms\n",
            "image 41/50 /content/datasets/Kibo-3/valid/images/post_4-8-_png.rf.fb53364450267cea98b5edbac5b05f1c.jpg: 800x800 1 diamond, 2 shells, 7.2ms\n",
            "image 42/50 /content/datasets/Kibo-3/valid/images/post_4-9-_png.rf.e18b40619fb665cfed3f145601bf1b49.jpg: 800x800 1 coral, 7.2ms\n",
            "image 43/50 /content/datasets/Kibo-3/valid/images/post_4_png.rf.d373c8c5f0697bba8e7f9c611e48858c.jpg: 800x800 1 emerald, 1 key, 7.2ms\n",
            "image 44/50 /content/datasets/Kibo-3/valid/images/post_5-11-_png.rf.231cd8fc7f1b1823e145d80141cb4648.jpg: 800x800 1 crystal, 1 key, 1 letter, 7.2ms\n",
            "image 45/50 /content/datasets/Kibo-3/valid/images/post_5-17-_png.rf.696037c53b4857489f87fc31f9a3b1b0.jpg: 800x800 1 Treasure_box, 1 crystal, 1 shell, 7.2ms\n",
            "image 46/50 /content/datasets/Kibo-3/valid/images/post_5-6-_png.rf.f53de011e5730e6f89e94d7439c8cdfd.jpg: 800x800 1 compass, 1 emerald, 1 key, 7.5ms\n",
            "image 47/50 /content/datasets/Kibo-3/valid/images/post_5-7-_png.rf.afef37ed96590b3ec90f8a2f86c390b3.jpg: 800x800 1 emerald, 1 fossil, 1 key, 7.2ms\n",
            "image 48/50 /content/datasets/Kibo-3/valid/images/post_5-8-_png.rf.caab7be565cbe4ba5173c6b4cd27df32.jpg: 800x800 1 coral, 1 crystal, 1 key, 7.5ms\n",
            "image 49/50 /content/datasets/Kibo-3/valid/images/post_5-9-_png.rf.e6ed7be0d0e8a75a7eab2e3d04a73bd4.jpg: 800x800 1 compass, 1 coral, 1 emerald, 7.2ms\n",
            "image 50/50 /content/datasets/Kibo-3/valid/images/post_5_png.rf.210aa34a300c474a58808fcad5b15cf3.jpg: 800x800 1 Treasure_box, 1 diamond, 1 fossil, 7.2ms\n",
            "Speed: 5.1ms preprocess, 8.6ms inference, 4.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.50 source={dataset.location}/valid/images save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYIo95n-I0S"
      },
      "source": [
        "**NOTE:** Let's take a look at few results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "jbVjEtPAkz3j",
        "outputId": "75b0dc09-4e77-455e-b8ec-0f0bf1c7f55a"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "max() arg is an empty sequence",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-59bacfcfada8>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Find the latest folder by modification time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlatest_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{latest_folder}/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Define the base path where the folders are located\n",
        "base_path = '/content/drive/MyDrive/Yolo/runs'\n",
        "\n",
        "# List all directories that start with 'predict' in the base path\n",
        "subfolders = [os.path.join(base_path, d) for d in os.listdir(base_path)\n",
        "              if os.path.isdir(os.path.join(base_path, d)) and d.startswith('predict')]\n",
        "\n",
        "# Find the latest folder by modification time\n",
        "latest_folder = max(subfolders, key=os.path.getmtime)\n",
        "\n",
        "image_paths = glob.glob(f'{latest_folder}/*.jpg')[:3]\n",
        "\n",
        "# Display each image\n",
        "for image_path in image_paths:\n",
        "    display(Image(filename=image_path, width=600))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0tsVilOCPyq"
      },
      "source": [
        "## Deploy model on Roboflow\n",
        "\n",
        "Once you have finished training your YOLOv8 model, you’ll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n",
        "\n",
        "The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv8 weights.\n",
        "\n",
        "To upload model weights, add the following code to the “Inference with Custom Model” section in the aforementioned notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbP4_4C8fc0R",
        "outputId": "d8c6fa56-7fee-42e0-9b4f-aebc5e67841d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dependency ultralytics==8.0.196 is required but found version=8.2.103, to fix: `pip install ultralytics==8.0.196`\n",
            "Would you like to continue with the wrong version of ultralytics? y/n: y\n",
            "View the status of your deployment at: https://app.roboflow.com/model-examples/football-players-obj-detection/2\n",
            "Share your model with the world at: https://universe.roboflow.com/model-examples/football-players-obj-detection/model/2\n"
          ]
        }
      ],
      "source": [
        "project.version(dataset.version).deploy(model_type=\"yolov8\", model_path=f\"{HOME}/runs/detect/train/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQZk9Amyfq6F"
      },
      "source": [
        "Follow the links above to check if the upload succeeded. It may take a couple of minutes until the model is visible to the `roboflow` SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4bpUIibcV1l",
        "outputId": "ebf8e168-349e-4546-cee2-a2e4a81864e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running inference on 4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'predictions': [{'x': 1227.0,\n",
              "   'y': 527.5,\n",
              "   'width': 50.0,\n",
              "   'height': 77.0,\n",
              "   'confidence': 0.9045102000236511,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '7bb0de78-c58d-454a-b693-c3f518f94f80',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 731.0,\n",
              "   'y': 584.5,\n",
              "   'width': 52.0,\n",
              "   'height': 79.0,\n",
              "   'confidence': 0.8924632668495178,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': 'b3ea8a5a-5294-45c9-9221-ba8a6f0884b5',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 1397.5,\n",
              "   'y': 344.5,\n",
              "   'width': 31.0,\n",
              "   'height': 55.0,\n",
              "   'confidence': 0.8912790417671204,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '5ef87756-163e-442c-ad88-35f3572750d5',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 1447.0,\n",
              "   'y': 476.5,\n",
              "   'width': 32.0,\n",
              "   'height': 73.0,\n",
              "   'confidence': 0.8694518804550171,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '89a9e4d7-0b7b-4cc0-8596-cf90522a5f86',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 1271.0,\n",
              "   'y': 583.0,\n",
              "   'width': 36.0,\n",
              "   'height': 82.0,\n",
              "   'confidence': 0.8614903688430786,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '74b59e7e-03a8-477c-bb65-872b55cee6d2',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 332.5,\n",
              "   'y': 474.0,\n",
              "   'width': 33.0,\n",
              "   'height': 72.0,\n",
              "   'confidence': 0.8610998392105103,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '50984141-2378-4a7d-8b40-9e353bcf50d9',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 513.5,\n",
              "   'y': 379.5,\n",
              "   'width': 43.0,\n",
              "   'height': 57.0,\n",
              "   'confidence': 0.8593119978904724,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '131a232d-1403-498c-8714-ee9bc72768f1',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 1050.5,\n",
              "   'y': 404.0,\n",
              "   'width': 25.0,\n",
              "   'height': 66.0,\n",
              "   'confidence': 0.8461295962333679,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '17c1060d-60c1-4684-8190-99f32976e3b6',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 1524.0,\n",
              "   'y': 468.5,\n",
              "   'width': 28.0,\n",
              "   'height': 75.0,\n",
              "   'confidence': 0.8449162244796753,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': 'b78f434e-4fe3-4d7f-969c-2b540118a036',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 862.0,\n",
              "   'y': 299.0,\n",
              "   'width': 18.0,\n",
              "   'height': 46.0,\n",
              "   'confidence': 0.8436365723609924,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': 'a04d6b50-dfae-4bd3-934a-7c535ae86a6d',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 286.0,\n",
              "   'y': 409.0,\n",
              "   'width': 28.0,\n",
              "   'height': 66.0,\n",
              "   'confidence': 0.8423029780387878,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': 'd4868dd9-213d-4242-b5f4-b0a28bfa5c51',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 1113.0,\n",
              "   'y': 398.5,\n",
              "   'width': 22.0,\n",
              "   'height': 65.0,\n",
              "   'confidence': 0.8421118855476379,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '808cbedf-7404-41a5-ac38-61a46bfab755',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 867.5,\n",
              "   'y': 447.0,\n",
              "   'width': 25.0,\n",
              "   'height': 70.0,\n",
              "   'confidence': 0.8394479155540466,\n",
              "   'class': 'referee',\n",
              "   'class_id': 3,\n",
              "   'detection_id': '3e0537d1-ca58-438c-9323-702e21ddacd2',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 803.0,\n",
              "   'y': 461.5,\n",
              "   'width': 26.0,\n",
              "   'height': 69.0,\n",
              "   'confidence': 0.8217413425445557,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': 'bbdcdcff-9007-4311-96e3-e8a5079f177e',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 832.5,\n",
              "   'y': 475.5,\n",
              "   'width': 29.0,\n",
              "   'height': 67.0,\n",
              "   'confidence': 0.8183465003967285,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '9ff9c162-4288-42c4-a90c-c67983551391',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 593.5,\n",
              "   'y': 386.5,\n",
              "   'width': 25.0,\n",
              "   'height': 57.0,\n",
              "   'confidence': 0.7829996943473816,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '0898f653-a519-4c0d-abf4-c2f07c38be51',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 647.0,\n",
              "   'y': 421.0,\n",
              "   'width': 36.0,\n",
              "   'height': 64.0,\n",
              "   'confidence': 0.771634578704834,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': '599da973-e6b5-4d13-b990-480f7a58b083',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 737.0,\n",
              "   'y': 239.5,\n",
              "   'width': 24.0,\n",
              "   'height': 35.0,\n",
              "   'confidence': 0.7465640902519226,\n",
              "   'class': 'referee',\n",
              "   'class_id': 3,\n",
              "   'detection_id': 'ba786450-37a1-46bf-a80a-b28eb7252058',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'},\n",
              "  {'x': 1552.5,\n",
              "   'y': 404.5,\n",
              "   'width': 27.0,\n",
              "   'height': 67.0,\n",
              "   'confidence': 0.6716049909591675,\n",
              "   'class': 'player',\n",
              "   'class_id': 2,\n",
              "   'detection_id': 'fd36f2e9-6911-4d9e-93cd-3bd5b75263d0',\n",
              "   'image_path': '/content/datasets/football-players-obj-detection-1/test/images/4b770a_3_9_png.rf.26fd0dc802e143501b91eddef365a94d.jpg',\n",
              "   'prediction_type': 'ObjectDetectionModel'}],\n",
              " 'image': {'width': '1920', 'height': '1080'}}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run inference on your model on a persistent, auto-scaling, cloud API\n",
        "\n",
        "# Load model\n",
        "model = project.version(dataset.version).model\n",
        "assert model, \"Model deployment is still loading\"\n",
        "\n",
        "# Choose a random test image\n",
        "import os, random\n",
        "test_set_loc = dataset.location + \"/test/images/\"\n",
        "random_test_image = random.choice(os.listdir(test_set_loc))\n",
        "print(\"running inference on \" + random_test_image)\n",
        "\n",
        "pred = model.predict(test_set_loc + random_test_image, confidence=40, overlap=30).json()\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZRK3zxS2m1n"
      },
      "source": [
        "# Deploy Your Model to the Edge\n",
        "\n",
        "In addition to using the Roboflow hosted API for deployment, you can use [Roboflow Inference](https://inference.roboflow.com), an open source inference solution that has powered millions of API calls in production environments. Inference works with CPU and GPU, giving you immediate access to a range of devices, from the NVIDIA Jetson to TRT-compatible devices to ARM CPU devices.\n",
        "\n",
        "With Roboflow Inference, you can self-host and deploy your model on-device. You can deploy applications using the [Inference Docker containers](https://inference.roboflow.com/quickstart/docker/) or the pip package.\n",
        "\n",
        "For example, to install Inference on a device with an NVIDIA GPU, we can use:\n",
        "\n",
        "```\n",
        "docker pull roboflow/roboflow-inference-server-gpu\n",
        "```\n",
        "\n",
        "Then we can run inference via HTTP:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "workspace_id = \"\"\n",
        "model_id = \"\"\n",
        "image_url = \"\"\n",
        "confidence = 0.75\n",
        "api_key = \"\"\n",
        "\n",
        "infer_payload = {\n",
        "    \"image\": {\n",
        "        \"type\": \"url\",\n",
        "        \"value\": image_url,\n",
        "    },\n",
        "    \"confidence\": confidence,\n",
        "    \"iou_threshold\": iou_thresh,\n",
        "    \"api_key\": api_key,\n",
        "}\n",
        "res = requests.post(\n",
        "    f\"http://localhost:9001/{workspace_id}/{model_id}\",\n",
        "    json=infer_object_detection_payload,\n",
        ")\n",
        "\n",
        "predictions = res.json()\n",
        "```\n",
        "\n",
        "Above, set your Roboflow workspace ID, model ID, and API key.\n",
        "\n",
        "- [Find your workspace and model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids?ref=blog.roboflow.com)\n",
        "- [Find your API key](https://docs.roboflow.com/api-reference/authentication?ref=blog.roboflow.com#retrieve-an-api-key)\n",
        "\n",
        "Also, set the URL of an image on which you want to run inference. This can be a local file.\n",
        "\n",
        "_To use your YOLOv5 model commercially with Inference, you will need a Roboflow Enterprise license, through which you gain a pass-through license for using YOLOv5. An enterprise license also grants you access to features like advanced device management, multi-model containers, auto-batch inference, and more._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovQgOj_xSNDg"
      },
      "source": [
        "## 🏆 Congratulations\n",
        "\n",
        "### Learning Resources\n",
        "\n",
        "Roboflow has produced many resources that you may find interesting as you advance your knowledge of computer vision:\n",
        "\n",
        "- [Roboflow Notebooks](https://github.com/roboflow/notebooks): A repository of over 20 notebooks that walk through how to train custom models with a range of model types, from YOLOv7 to SegFormer.\n",
        "- [Roboflow YouTube](https://www.youtube.com/c/Roboflow): Our library of videos featuring deep dives into the latest in computer vision, detailed tutorials that accompany our notebooks, and more.\n",
        "- [Roboflow Discuss](https://discuss.roboflow.com/): Have a question about how to do something on Roboflow? Ask your question on our discussion forum.\n",
        "- [Roboflow Models](https://roboflow.com): Learn about state-of-the-art models and their performance. Find links and tutorials to guide your learning.\n",
        "\n",
        "### Convert data formats\n",
        "\n",
        "Roboflow provides free utilities to convert data between dozens of popular computer vision formats. Check out [Roboflow Formats](https://roboflow.com/formats) to find tutorials on how to convert data between formats in a few clicks.\n",
        "\n",
        "### Connect computer vision to your project logic\n",
        "\n",
        "[Roboflow Templates](https://roboflow.com/templates) is a public gallery of code snippets that you can use to connect computer vision to your project logic. Code snippets range from sending emails after inference to measuring object distance between detections."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}